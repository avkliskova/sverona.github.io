<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>S. Verona Malone</title><link>./</link><description>Recent content on S. Verona Malone</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 08 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="./index.xml" rel="self" type="application/rss+xml"/><item><title>Abstract</title><link>./blog/thesis/abstract/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/abstract/</guid><description/></item><item><title>Introduction</title><link>./blog/thesis/introduction/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/introduction/</guid><description/></item><item><title>Lattice theory</title><link>./blog/thesis/lattice-theory/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/lattice-theory/</guid><description>This section and the next introduce the mathematics necessary to read Chapter 3. The main results draw from combinatorial lattice theory and the representation theory of Lie algebras.
In this section we present a number of standard definitions and notions concerning posets and lattices, in particular the diamond-colored distributive lattices (DCDLs). DCDLs provide the setting for the graph-theoretic arguments and algorithms appearing in the sequel.
The primary references for this section are [Donnelly 2018] Robert G.</description></item><item><title>Lie theory</title><link>./blog/thesis/lie-theory/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/lie-theory/</guid><description>A full exposition of the theory of Lie algebras and their representations is well beyond the scope of this paper. We provide here only the necessary definitions and theorems to read §3.
We loosely follow [Humphreys 1972] James E. Humphreys. Introduction to Lie algebras and representation theory. Springer-Verlag, 1972. An introduction to the subject more suitable for advanced undergraduates is [@erdmann-wildon].
A Lie algebra is a vector space \(\mathfrak g\) together with a bracket operation \([ \cdot, \cdot ] : \mathfrak g \times \mathfrak g \to \mathfrak g\) satisfying the following axioms for each \(x, y, z \in \mathfrak g\) and scalars \(a, b\):</description></item><item><title>Supporting graphs</title><link>./blog/thesis/supporting-graphs/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/supporting-graphs/</guid><description>We now present the centerpiece of the work. Throughout, write \([n] = \mathbb N \cap [1, n].\)
The DCS relations Let \(L\) be a diamond-colored distributive lattice with edges colored by \([n]\), and let \(x \in L\). For each \(i \in \mathbb N\), let \(\top_i(x) \in L\) be the maximum element of the \(i\)-component in which \(x\) lies.
Define a weight function The quantity \(\rho_i(\top_i(x)) - \rho_i(x))\) is the distance of \(x\) “from the top” of its \(i\)-component, whereas \(\rho_i(x)\) is the distance of \(x\) “from the bottom.</description></item><item><title>Catalanian lattices</title><link>./blog/thesis/catalanian-lattices/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/catalanian-lattices/</guid><description>This section introduces and proves the author's main results.
Gelfand-Tsetlin patterns A Gelfand-Tsetlin pattern or just GT pattern of order \(n\) is an \(n \times n\) lower triangular matrix with integer entries that satisfies \(g_{i + 1, j} \leq g_{ij} \leq g_{i +1, j + 1}\) for any \(1 \leq j \leq i \leq n.\) This definition is equivalent to that given in [@stanley-ec2] §7.10. We represent GT patterns as matrices here for ease of computation and typesetting.</description></item><item><title>Paths and tableaux</title><link>./blog/thesis/motzkin-paths/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/motzkin-paths/</guid><description>Motzkin paths A topside peakless Motzkin path of length \(n\) is a sequence \({p_i}_{i=1}^n\) such that for each \(1 \leq i \leq n,\)
\(p_i \in {-1, 0, 1};\) \(\sum_{k=1}^i p_k \geq 0;\) if \(p_{i - 1} = 1\), \(p_i \not = -1,\) and for which \(\sum_{i=1}^n p_i = 0.\) By calling \({p_i}_{i=1}^n\) a &amp;ldquo;path,&amp;rdquo; we mean to identify it with the series of points \({(i, \sum_{k=1}^i p_k)}_{i=1}^n\). The above definition then says</description></item><item><title>Computational methods</title><link>./blog/thesis/computational-methods/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>./blog/thesis/computational-methods/</guid><description>This chapter outlines the Python code provided in Appendix A.
Overview of the dc-lattices library In this section we describe the contents of each file listed in Appendix A.
dc_lattice.py contains the abstract initialization and population routines for generic DCDLs. We model a DCDL as a graph using the networkx library.
incremental_lattice.py overrides some methods in dc_lattice.py to handle generic /incremental/ lattices (which, it should be noted, includes every example in this thesis.</description></item><item><title>Mimicking LaTeX theorem environments with CSS</title><link>./blog/mimicking-latex-theorem-environments-with-css/</link><pubDate>Sun, 08 Aug 2021 00:00:00 +0000</pubDate><guid>./blog/mimicking-latex-theorem-environments-with-css/</guid><description>LaTeX supports &amp;ldquo;theorem environments,&amp;rdquo; like this:
(Image)
These aren&amp;rsquo;t hard to mimic with :before and :after:
article { counter-reset: definition theorem lemma example proposition corollary; } .definition:before { counter-increment: definition; content: &amp;#34;Definition &amp;#34; counter(definition) &amp;#34;.&amp;#34;; font-weight: bold; } .theorem:before { counter-increment: theorem; content: &amp;#34;Theorem &amp;#34; counter(theorem) &amp;#34;.&amp;#34;; font-weight: bold; } .lemma:before { counter-increment: lemma; content: &amp;#34;Lemma &amp;#34; counter(lemma) &amp;#34;.&amp;#34;; font-weight: bold; } .example:before { counter-increment: example; content: &amp;#34;Example &amp;#34; counter(example) &amp;#34;.</description></item><item><title>\(\pi\) and \(e\) and the GCD</title><link>./blog/gcd-ln/</link><pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate><guid>./blog/gcd-ln/</guid><description>While doing some research for my Project Euler post, I found myself drawn to something else that blew my mind in high school &amp;mdash; the connection between the greatest common divisor and the Riemann zeta function.
For those of you just joining us:
The greatest common divisor of two nonzero integers is the largest positive number that divides them both. The Riemann zeta function is the series \[\zeta(s) = \sum_{n = 1}^\infty \frac1{n^s} = \frac1{1^s} + \frac1{2^s} + \frac1{3^s} + \cdots.</description></item><item><title>Project Euler 1-100 in 49 hours</title><link>./blog/project-euler/</link><pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate><guid>./blog/project-euler/</guid><description>Project Euler is how I taught myself Python in high school, and so I find it incredibly nostalgic. It took 13-year-old me a lot of Googling and a few months to get through the first 100 problems.
10-odd years and a graduate degree later, I decided to come back and solve them as fast as I could. I&amp;rsquo;m no competitive programmer, but 24 hours seemed reasonable. Fortunately, I lack the stamina to code for that long, so I did it over a few days instead.</description></item><item><title>Neural networks in time scale calculus</title><link>./blog/nabla/</link><pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate><guid>./blog/nabla/</guid><description>Neural networks are a popular technique for machine learning problems such as automated handwriting recognition, automated speech recognition, and time-series forecasting. On these tasks, so-called deep neural networks [Schmidhuber 2015] and convolutional neural networks [Ciresan et al. 2011] have performed at least as well as the best known non-neural-network statistical learning techniques. A typical neural network numerically solves an extremization problem using gradient descent in a high-dimensional Euclidean space using an algorithm known as backpropagation.</description></item><item><title>The dual simplex method, an introduction</title><link>./blog/dual-simplex/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>./blog/dual-simplex/</guid><description>The primal simplex method provides an algorithmic means for solving linear programs (hereinafter LPs.) This document motivates, defines, and applies the so-called dual simplex method, a slight variant which is useful for performing post hoc sensitivity analysis on LPs solved by the simplex method.
The primal simplex method In this section, we review the three steps of the usual primal method, following [Hillier-Lieberman], Frederick S. Hillier and Gerald J. Lieberman, Introduction to operations research, 10th ed.</description></item></channel></rss>